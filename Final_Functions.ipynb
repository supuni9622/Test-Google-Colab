{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Functions.ipynb",
      "provenance": [],
      "mount_file_id": "1H-Pxf1isHuqYitwkkkF9426WGil1caxa",
      "authorship_tag": "ABX9TyNRi/W6GSneGvNAoQ5H4O9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supuni9622/Test-Google-Colab/blob/main/Final_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9EyZ30YCd7L",
        "outputId": "533daa4f-df78-4cda-b30d-c0b4cadcd5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/Full\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/Full"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and packages"
      ],
      "metadata": {
        "id": "pMbpuSpsuPp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import plot_confusion_matrix \n",
        "import seaborn as sns\n",
        "from numpy import random"
      ],
      "metadata": {
        "id": "v4LgfTRIuYRd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Datasets, Data Preporation and Visualization"
      ],
      "metadata": {
        "id": "LgtnmzaFvat2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Datasets**"
      ],
      "metadata": {
        "id": "1u67PRS6vu7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hVvQQz-Cvp2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing - Musical Data**"
      ],
      "metadata": {
        "id": "tUN86TmHwCTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_E14C1-lwOc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing - Lyrical Data**"
      ],
      "metadata": {
        "id": "rXdc7G9CwQuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QX6SBhynwWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization - Musical Data**"
      ],
      "metadata": {
        "id": "rCokb-b8wXe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D_palzKRwdRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization - Lyrical Data**"
      ],
      "metadata": {
        "id": "CtbiCwLWwdnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9BtVwfJSwidZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Classification Using Genre and Music Elements"
      ],
      "metadata": {
        "id": "EJIDFiXpu4ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "YebYYmiRw6qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E5VWfcLswyFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Testing**"
      ],
      "metadata": {
        "id": "oPbgoTjQw95q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "liRqRbMHxKKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter Optimisation**"
      ],
      "metadata": {
        "id": "7hK4ad98xKsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U4j8wSH6xQYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Validation and Evaluation**"
      ],
      "metadata": {
        "id": "ti9Gi7rrxSkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KNXA1a8HxiiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Classification Using Lyrical Data"
      ],
      "metadata": {
        "id": "vB6trvFkxnzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "SgFWv7IKxv_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4l9SCXloxzg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Testing**"
      ],
      "metadata": {
        "id": "wXYWjHTzxz_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PovC_QTVx2_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter Optimization**"
      ],
      "metadata": {
        "id": "fpfQ06kcx3gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eu-7QJw1x85a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Validation and Evaluation**"
      ],
      "metadata": {
        "id": "xuS8PBYax-Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SnEsDFNhyDof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human Emotion - Song Emotion Matrix"
      ],
      "metadata": {
        "id": "8Wad3kBjyl0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VbN2mOxVy0Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Song - Song Emotion Matrix"
      ],
      "metadata": {
        "id": "6sseIHZuy1ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert music-emotion to matrix**"
      ],
      "metadata": {
        "id": "5c9qQLxkzFmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N5FuhTVjzLxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert lyrical-emotion to matrix**"
      ],
      "metadata": {
        "id": "hDSRPxXTzMTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8CnwWh6gzgwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined Matrix**"
      ],
      "metadata": {
        "id": "-qpZ9z_HzhEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zg6oh-vFzlGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human emotion - Songs Suitability Score Matrix"
      ],
      "metadata": {
        "id": "o2bAW5RIzxou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7vx_pTXwz5nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "uoetwJd30GTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default user emotion and song's attributes"
      ],
      "metadata": {
        "id": "uLaAjiKf0Q45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_emo = 'Happy'\n",
        "#Thre is a oder - Genre, Music elements, Lyrics\n",
        "music_attributes = []"
      ],
      "metadata": {
        "id": "zWl2UYAs0YhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict music emotion"
      ],
      "metadata": {
        "id": "1FWmA17V0dwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_music_emotion(music_attributes):\n",
        "    # Emotion classification based on the music elements \n",
        "    predicted_emo = 'Happy'\n",
        "    return predicted_emo"
      ],
      "metadata": {
        "id": "3MvzNPGb0kNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict lyrical emotion"
      ],
      "metadata": {
        "id": "MDGsV3bM0moO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lyrical_emotion(music_attributes):\n",
        "    #Lyrics classification based on the lyrics\n",
        "    predicted_emo = 'Calm'\n",
        "    return predicted_emo"
      ],
      "metadata": {
        "id": "Cy_AxtSj0qLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to emotion vector"
      ],
      "metadata": {
        "id": "3XRJ_sxO0s7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_emo_vector(emotion):\n",
        "    #Has 7 music emotions and convert to emo vector by putting 1 to recived emo type\n",
        "    \n",
        "    predifend_set = [0,0,0,0,0,0,0]\n",
        "    emo_vector = [1,0,0,0,0,0,0]\n",
        "    return emo_vector"
      ],
      "metadata": {
        "id": "qeyp-bCs0307"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get emotion vector"
      ],
      "metadata": {
        "id": "3_BiBR5w08d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emotion_vector(music_emotion, lyrical_emotion):\n",
        "    #Convert to a vector of selected 7 music emotion types\n",
        "    \n",
        "    music_weight = 2\n",
        "    lyrical_weight = 1\n",
        "\n",
        "    if(music_emotion == 'Happy' | music_emotion == 'Calm'):\n",
        "        if(lyrical_emotion == 'Happy' | lyrical_emotion == 'Calm'):\n",
        "            music_weight = 2\n",
        "            lyrical_weight = 1\n",
        "        else:\n",
        "            music_weight =2\n",
        "            lyrical_weight=2\n",
        "    else:\n",
        "        if(lyrical_emotion == 'Happy' | lyrical_emotion == 'Calm'):\n",
        "            music_weight = 1\n",
        "            lyrical_weight = 1\n",
        "        else:\n",
        "            music_weight =1\n",
        "            lyrical_weight=2\n",
        "        return music_weight, lyrical_weight\n",
        "\n",
        "    music_emo_vector = music_weight * get_emotion_vector(music_emotion)\n",
        "    lyrical_emo_vector = lyrical_weight * get_emotion_vector(lyrical_emotion)\n",
        "    emo_vector = music_emo_vector + lyrical_emo_vector\n",
        "    emo_vector = [[1,0,2,0,0,0,0]]\n",
        "    return emo_vector"
      ],
      "metadata": {
        "id": "Wn2TYhC90-Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get suitability score"
      ],
      "metadata": {
        "id": "4UnFxhc51ENN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suitability_score(emo_vector):\n",
        "    #Predefined human-emotion(18), music-emotion(7) matrix [18,7]\n",
        "    human_music_emo_matrix = [\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0],\n",
        "        [1,-1,-1,0,1,0,0]\n",
        "    ]\n",
        "\n",
        "    #This traspose is [7,1]\n",
        "    emo_vector_transpose = [[1],\n",
        "                        [0],\n",
        "                        [2],\n",
        "                        [0],\n",
        "                        [0],\n",
        "                        [0],\n",
        "                        [0]]\n",
        "\n",
        "    #This should be a [18,1]\n",
        "    suitability_score = [[1],\n",
        "                     [-2],\n",
        "                     [1],\n",
        "                     [0],\n",
        "                     [1],\n",
        "                     [-2],\n",
        "                     [1],\n",
        "                     [0],\n",
        "                     [1],\n",
        "                     [-2],\n",
        "                     [1],\n",
        "                     [0],\n",
        "                     [1],\n",
        "                     [-2],\n",
        "                     [1],\n",
        "                     [0],\n",
        "                     [1],\n",
        "                     [-2]\n",
        "                     ]\n",
        "    return suitability_score"
      ],
      "metadata": {
        "id": "fIDzT4en1GeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert output to a readable format"
      ],
      "metadata": {
        "id": "_f9-hQ7D1dxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_output_to_readable_format(user_emo, suitability_score_vector):\n",
        "    if(user_emo == ''):\n",
        "        #Return all the scores for 18 emo types as a data frame and readble format\n",
        "        suitability = {'Happy' : 1, 'Sad' : -1, 'Calm' : 0}\n",
        "        return suitability\n",
        "    else:\n",
        "        return suitability.user_emo"
      ],
      "metadata": {
        "id": "mYUYPqOB1hth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get suitability score of a song"
      ],
      "metadata": {
        "id": "Wi7BNzDj1lIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Function\n",
        "def get_suitability_score_of_song(user_emo, music_attributes):\n",
        "    \n",
        "    music_emotion = get_music_emotion(music_attributes.iloc[:,0:8].values)\n",
        "    lyrical_emotion = get_lyrical_emotion(music_attributes.iloc[:, -1].values)\n",
        "    \n",
        "    emo_vector = get_emotion_vector(music_emotion, lyrical_emotion)\n",
        "    \n",
        "    suitability_score_vector = get_suitability_score(emo_vector)\n",
        "    \n",
        "    readable_output = convert_output_to_readable_format(user_emo, suitability_score_vector)\n",
        "    \n",
        "    return readable_output"
      ],
      "metadata": {
        "id": "KKYBO0a61p68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = get_suitability_score_of_song('', [])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "h4dzvU21DkWB",
        "outputId": "208ad8ef-2625-43cd-edbb-70837efdc553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-abe39fc49cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_suitability_score_of_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-0a158bfd4014>\u001b[0m in \u001b[0;36mget_suitability_score_of_song\u001b[0;34m(user_emo, music_attributes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_suitability_score_of_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_emo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmusic_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mmusic_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_music_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_attributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mlyrical_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lyrical_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_attributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
          ]
        }
      ]
    }
  ]
}