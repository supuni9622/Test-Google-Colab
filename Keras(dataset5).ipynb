{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras(dataset5).ipynb",
      "provenance": [],
      "mount_file_id": "1H2NL19CG55Z7SE_OWs8m6JpLTncnQ1tY",
      "authorship_tag": "ABX9TyOxaidgKITeaWxXiDlet6nM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supuni9622/Test-Google-Colab/blob/main/Keras(dataset5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuDTYauwZ2Mi",
        "outputId": "503ed9d3-cd7b-4dc9-9730-6a9a80c18662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/TestV2/TFID\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/TestV2/TFID"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import regularizers, optimizers\n",
        "from keras.layers import TextVectorization\n",
        "from keras.layers import Embedding, Dense, Dropout, Input, LSTM, GlobalMaxPool1D\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "import tensorflow as tf\n",
        "import spacy"
      ],
      "metadata": {
        "id": "lYaMCFwyaMOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and import the large english model.\n",
        "!python -m spacy download en_core_web_lg\n",
        "import en_core_web_lg\n",
        "\n",
        "nlp = en_core_web_lg.load()\n",
        "Vectorizer = TextVectorization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm5d0q0ObEcd",
        "outputId": "5c92802a-3f5e-4243-fba7-181410238dec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=38b74cad6bd41c6b80a7a8e6e4c2b4f73d02461311f96e10ca177b2122173e22\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lxthrc5b/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Lyrical_data_5.csv',encoding='cp1252')\n",
        "df = df.dropna(how=\"any\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "9Osdcqrrab1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "REPLACE = re.compile('[^a-zA-Z]')\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE.sub(' ', text)\n",
        "    #text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL65HtQoazgA",
        "outputId": "bce2c4e8-1af1-49df-e936-ab28be7feb9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Chorus'] = df['Chorus'].apply(clean_text)"
      ],
      "metadata": {
        "id": "dtsqXEkba7zp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible_labels = df.Emotion.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2U3VPJQeJE4",
        "outputId": "695bb537-724f-4447-c584-4da0b556d353"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Angry': 4, 'Calm': 3, 'Happy': 5, 'Inspiration': 0, 'Love': 1, 'Sad': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df.Emotion.replace(label_dict)"
      ],
      "metadata": {
        "id": "cxPpEdwCeM2u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the vectorizer on the text and extract the corpus vocabulary\n",
        "Vectorizer.adapt(df.Chorus.to_numpy())\n",
        "vocab = Vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "id": "Q1KqbqR4ao01"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the embedding matrix\n",
        "num_tokens = len(vocab)\n",
        "embedding_dim = len(nlp('The').vector)\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for i, word in enumerate(vocab):\n",
        "    embedding_matrix[i] = nlp(str(word)).vector"
      ],
      "metadata": {
        "id": "gP4YqvJSb8_r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the embedding matrix as the weights matrix for the embedding layer and set trainable to False\n",
        "Embedding_layer=Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=Constant(embedding_matrix),\n",
        "    trainable=False)"
      ],
      "metadata": {
        "id": "rgrrDUB8cd6A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model.  This is a bigger one, but it works well on this problem.\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(Vectorizer)\n",
        "model.add(Embedding_layer)\n",
        "model.add(LSTM(25, return_sequences=True))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='tanh', \n",
        "                kernel_regularizer = regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='tanh', \n",
        "                kernel_regularizer = regularizers.l1_l2(l1=1e-5, l2=1e-4)))    \n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mean_absolute_error', metrics = None)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoiXcO-aciZV",
        "outputId": "3bcdffe8-d023-4441-8727-a224da94805f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 300)         1052700   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, None, 25)          32600     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 25)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 25)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                832       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,087,221\n",
            "Trainable params: 34,521\n",
            "Non-trainable params: 1,052,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuo5XcU4dqqe",
        "outputId": "facd6abd-6171-4512-c11d-b13d61dbd24d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 800 entries, 0 to 799\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Song_ID     800 non-null    int64 \n",
            " 1   Song_Title  800 non-null    object\n",
            " 2   Chorus      800 non-null    object\n",
            " 3   Emotion     800 non-null    object\n",
            " 4   label       800 non-null    int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 31.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model\n",
        "model.fit(df.Chorus,\n",
        "          df.label,\n",
        "          batch_size = 10,\n",
        "          epochs = 50,\n",
        "          validation_split=0.2,\n",
        "          shuffle = True\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KN7pBMudHRs",
        "outputId": "e49ab1fe-0f5d-48b9-d72b-474e42794532"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "64/64 [==============================] - 2s 30ms/step - loss: 0.5276 - val_loss: 1.4162\n",
            "Epoch 2/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.5238 - val_loss: 1.3876\n",
            "Epoch 3/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.5027 - val_loss: 1.3940\n",
            "Epoch 4/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.5254 - val_loss: 1.3868\n",
            "Epoch 5/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4777 - val_loss: 1.4168\n",
            "Epoch 6/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.5167 - val_loss: 1.4302\n",
            "Epoch 7/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4932 - val_loss: 1.4103\n",
            "Epoch 8/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.5154 - val_loss: 1.3834\n",
            "Epoch 9/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4836 - val_loss: 1.3980\n",
            "Epoch 10/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4837 - val_loss: 1.3619\n",
            "Epoch 11/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4833 - val_loss: 1.3784\n",
            "Epoch 12/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4694 - val_loss: 1.3880\n",
            "Epoch 13/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4630 - val_loss: 1.3882\n",
            "Epoch 14/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4674 - val_loss: 1.3801\n",
            "Epoch 15/50\n",
            "64/64 [==============================] - 2s 30ms/step - loss: 0.4753 - val_loss: 1.3565\n",
            "Epoch 16/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4538 - val_loss: 1.3727\n",
            "Epoch 17/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4775 - val_loss: 1.3548\n",
            "Epoch 18/50\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.4352 - val_loss: 1.3782\n",
            "Epoch 19/50\n",
            "64/64 [==============================] - 5s 74ms/step - loss: 0.4501 - val_loss: 1.3882\n",
            "Epoch 20/50\n",
            "64/64 [==============================] - 2s 32ms/step - loss: 0.4355 - val_loss: 1.3543\n",
            "Epoch 21/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4211 - val_loss: 1.3725\n",
            "Epoch 22/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4265 - val_loss: 1.3937\n",
            "Epoch 23/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4410 - val_loss: 1.4047\n",
            "Epoch 24/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4599 - val_loss: 1.3763\n",
            "Epoch 25/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4099 - val_loss: 1.3955\n",
            "Epoch 26/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4221 - val_loss: 1.3682\n",
            "Epoch 27/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4314 - val_loss: 1.3882\n",
            "Epoch 28/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4206 - val_loss: 1.3630\n",
            "Epoch 29/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4244 - val_loss: 1.3746\n",
            "Epoch 30/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4278 - val_loss: 1.4058\n",
            "Epoch 31/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4232 - val_loss: 1.3915\n",
            "Epoch 32/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4250 - val_loss: 1.5054\n",
            "Epoch 33/50\n",
            "64/64 [==============================] - 2s 30ms/step - loss: 0.5467 - val_loss: 1.3513\n",
            "Epoch 34/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4630 - val_loss: 1.3526\n",
            "Epoch 35/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4397 - val_loss: 1.3537\n",
            "Epoch 36/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4216 - val_loss: 1.3602\n",
            "Epoch 37/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4142 - val_loss: 1.3625\n",
            "Epoch 38/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4258 - val_loss: 1.3564\n",
            "Epoch 39/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4168 - val_loss: 1.4096\n",
            "Epoch 40/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4060 - val_loss: 1.3756\n",
            "Epoch 41/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4062 - val_loss: 1.3426\n",
            "Epoch 42/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.4307 - val_loss: 1.4013\n",
            "Epoch 43/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.3914 - val_loss: 1.3686\n",
            "Epoch 44/50\n",
            "64/64 [==============================] - 2s 30ms/step - loss: 0.3966 - val_loss: 1.3345\n",
            "Epoch 45/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.4134 - val_loss: 1.3442\n",
            "Epoch 46/50\n",
            "64/64 [==============================] - 2s 27ms/step - loss: 0.3866 - val_loss: 1.3872\n",
            "Epoch 47/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.3853 - val_loss: 1.4287\n",
            "Epoch 48/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.3777 - val_loss: 1.3912\n",
            "Epoch 49/50\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 0.3801 - val_loss: 1.3899\n",
            "Epoch 50/50\n",
            "64/64 [==============================] - 2s 28ms/step - loss: 0.3912 - val_loss: 1.3802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ac44465d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(df.Chorus,df.label)\n",
        "accr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJfYvKElfV-E",
        "outputId": "ae7f108b-ea3c-4fce-880f-60c0d573e2c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 16ms/step - loss: 0.5041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5041497349739075"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Pretrained Word Embeddings using SpaCy and Keras TextVectorization](https://towardsdatascience.com/pretrained-word-embeddings-using-spacy-and-keras-textvectorization-ef75ecd56360)"
      ],
      "metadata": {
        "id": "dgVJILHrgmAK"
      }
    }
  ]
}