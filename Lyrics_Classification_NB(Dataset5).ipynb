{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyrics Classification-NB(Dataset5).ipynb",
      "provenance": [],
      "mount_file_id": "12PwqUuHH96pcgy9XbfZkTSop4kGIi8tA",
      "authorship_tag": "ABX9TyN5UQmkvBPZxQ3eFjTBOHAa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supuni9622/Test-Google-Colab/blob/main/Lyrics_Classification_NB(Dataset5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGRsbfpSaJ_a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyqMtBqLbPPe",
        "outputId": "124c07ee-3dc9-478a-c596-83647888579e"
      },
      "source": [
        "cd /content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/TestV2/NB"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/4th Year Research/M3/Test Implementation/Test-Google-Colab/TestV2/NB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD5oKe9kaip_"
      },
      "source": [
        "dataset = pd.read_csv('Lyrical_data_5.csv',encoding='cp1252')"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSdSruceNU_J"
      },
      "source": [
        "dataset.dropna(how='all', axis=1, inplace=True)"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vvB4soGOFXP"
      },
      "source": [
        "Checking the empty rows in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKKWupuDOE-g",
        "outputId": "1bf63541-47ca-48d0-daeb-9b14fa9ebfd5"
      },
      "source": [
        "print (dataset.isnull().sum())"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Song_ID       0\n",
            "Song_Title    0\n",
            "Chorus        0\n",
            "Emotion       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhJtwuJObZu"
      },
      "source": [
        "modifiedDF = dataset.dropna()"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGlaPVebvyM",
        "outputId": "fd4537b1-e43d-440e-8355-814b792fc66b"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0, 799):\n",
        "  Lyrics = re.sub('[^a-zA-Z]', ' ', modifiedDF['Chorus'][i])\n",
        "  Lyrics = Lyrics.lower()\n",
        "  Lyrics = Lyrics.split()\n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  all_stopwords.remove('down')\n",
        "  all_stopwords.remove('over')\n",
        "  all_stopwords.remove('under')\n",
        "  all_stopwords.remove('no')\n",
        "  all_stopwords.remove('only')\n",
        "  all_stopwords.remove(\"don't\")\n",
        "  all_stopwords.remove(\"aren't\")\n",
        "  all_stopwords.remove(\"y\")\n",
        "  all_stopwords.remove(\"i\")\n",
        "  all_stopwords.remove(\"o\")\n",
        "  all_stopwords.remove(\"ma\")\n",
        "  all_stopwords.remove(\"didn't\")\n",
        "  all_stopwords.remove(\"can\")\n",
        "  all_stopwords.remove(\"be\")\n",
        "  all_stopwords.remove(\"to\")\n",
        "  all_stopwords.remove(\"for\")\n",
        "  all_stopwords.remove(\"you\")\n",
        "  all_stopwords.remove(\"your\")\n",
        "  all_stopwords.remove(\"we\")\n",
        "  all_stopwords.remove(\"our\")\n",
        "  all_stopwords.remove(\"my\")\n",
        "  all_stopwords.remove(\"you're\")\n",
        "  Lyrics = [ps.stem(word) for word in Lyrics if not word in set(all_stopwords)]\n",
        "  Lyrics = ' '.join(Lyrics)\n",
        "  corpus.append(Lyrics)"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV0uWOYCQWKF"
      },
      "source": [
        "Creating the bag of words modal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRT_E8GkQY4x"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1150)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = modifiedDF.iloc[0:799, -1].values"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmG9-Z7PQyea"
      },
      "source": [
        "Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PShXt3tuQzIx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o6BdfkSRnnC"
      },
      "source": [
        "Training the Naive Bayes model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TdKzzyyRoNv",
        "outputId": "4c1c01ea-fd0e-4113-8107-4a7551804c17"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maG3b8yiRup0"
      },
      "source": [
        "Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56RB62bSRvbY",
        "outputId": "35d7cbd6-3e23-48fd-e7cd-4da977a3c6af"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Sad' 'Sad']\n",
            " ['Inspiration' 'Angry']\n",
            " ['Calm' 'Happy']\n",
            " ['Happy' 'Inspiration']\n",
            " ['Love' 'Sad']\n",
            " ['Love' 'Sad']\n",
            " ['Happy' 'Happy']\n",
            " ['Calm' 'Sad']\n",
            " ['Angry' 'Angry']\n",
            " ['Sad' 'Love']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Happy' 'Love']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Love' 'Sad']\n",
            " ['Happy' 'Happy']\n",
            " ['Love' 'Sad']\n",
            " ['Sad' 'Sad']\n",
            " ['Happy' 'Happy']\n",
            " ['Sad' 'Sad']\n",
            " ['Love' 'Sad']\n",
            " ['Sad' 'Sad']\n",
            " ['Happy' 'Happy']\n",
            " ['Inspiration' 'Love']\n",
            " ['Sad' 'Sad']\n",
            " ['Angry' 'Inspiration']\n",
            " ['Inspiration' 'Calm']\n",
            " ['Sad' 'Love']\n",
            " ['Sad' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Love' 'Sad']\n",
            " ['Calm' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Sad' 'Happy']\n",
            " ['Angry' 'Happy']\n",
            " ['Love' 'Happy']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Calm' 'Love']\n",
            " ['Sad' 'Sad']\n",
            " ['Sad' 'Sad']\n",
            " ['Angry' 'Sad']\n",
            " ['Calm' 'Calm']\n",
            " ['Happy' 'Inspiration']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Inspiration' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Happy' 'Calm']\n",
            " ['Angry' 'Angry']\n",
            " ['Love' 'Love']\n",
            " ['Happy' 'Love']\n",
            " ['Sad' 'Angry']\n",
            " ['Love' 'Sad']\n",
            " ['Love' 'Inspiration']\n",
            " ['Happy' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Sad' 'Happy']\n",
            " ['Happy' 'Calm']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Calm' 'Inspiration']\n",
            " ['Sad' 'Angry']\n",
            " ['Inspiration' 'Happy']\n",
            " ['Angry' 'Angry']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Angry' 'Angry']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Love' 'Inspiration']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Happy' 'Happy']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Sad' 'Sad']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Happy']\n",
            " ['Happy' 'Sad']\n",
            " ['Inspiration' 'Calm']\n",
            " ['Calm' 'Love']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Sad' 'Sad']\n",
            " ['Angry' 'Angry']\n",
            " ['Inspiration' 'Love']\n",
            " ['Sad' 'Happy']\n",
            " ['Love' 'Love']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Love' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Love' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Happy' 'Angry']\n",
            " ['Inspiration' 'Happy']\n",
            " ['Angry' 'Angry']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Inspiration' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Angry' 'Sad']\n",
            " ['Sad' 'Love']\n",
            " ['Sad' 'Sad']\n",
            " ['Calm' 'Calm']\n",
            " ['Love' 'Sad']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Inspiration' 'Calm']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Sad' 'Sad']\n",
            " ['Happy' 'Angry']\n",
            " ['Sad' 'Calm']\n",
            " ['Angry' 'Sad']\n",
            " ['Calm' 'Calm']\n",
            " ['Happy' 'Happy']\n",
            " ['Sad' 'Inspiration']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Calm' 'Calm']\n",
            " ['Love' 'Sad']\n",
            " ['Love' 'Sad']\n",
            " ['Calm' 'Love']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Sad' 'Calm']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Sad' 'Sad']\n",
            " ['Love' 'Love']\n",
            " ['Inspiration' 'Happy']\n",
            " ['Love' 'Inspiration']\n",
            " ['Love' 'Love']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Sad' 'Calm']\n",
            " ['Happy' 'Sad']\n",
            " ['Love' 'Inspiration']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Sad' 'Happy']\n",
            " ['Sad' 'Sad']\n",
            " ['Inspiration' 'Sad']\n",
            " ['Love' 'Inspiration']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Love' 'Angry']\n",
            " ['Love' 'Sad']\n",
            " ['Calm' 'Calm']\n",
            " ['Sad' 'Angry']\n",
            " ['Inspiration' 'Calm']\n",
            " ['Love' 'Sad']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Love' 'Inspiration']\n",
            " ['Angry' 'Inspiration']\n",
            " ['Angry' 'Sad']\n",
            " ['Love' 'Love']\n",
            " ['Love' 'Love']\n",
            " ['Inspiration' 'Love']\n",
            " ['Inspiration' 'Calm']\n",
            " ['Angry' 'Inspiration']\n",
            " ['Inspiration' 'Inspiration']\n",
            " ['Angry' 'Sad']\n",
            " ['Happy' 'Happy']\n",
            " ['Love' 'Happy']\n",
            " ['Love' 'Love']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uiv0xDxR7c9"
      },
      "source": [
        "Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-taVWdyIR79B",
        "outputId": "86a8e0f0-4991-4a73-ee08-313886b83053"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  0  2  1  1  3]\n",
            " [ 0  5  2  5  0  3]\n",
            " [ 1  1  7  4  2  4]\n",
            " [ 3  1  2 14  6  6]\n",
            " [ 0  4  3  5 14  4]\n",
            " [ 5  1  2 12 13 18]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUsVbKXOUWsd"
      },
      "source": [
        "Appyling K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl-4bKUMUZro",
        "outputId": "f82ea771-426e-4e97-fe99-f053741cb74d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 32.55 %\n",
            "Standard Deviation: 0.59 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqL3rJ_tWA9b",
        "outputId": "b882ea3d-33ee-49d7-b457-be315ccd22fd"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 30.68 %\n",
            "Standard Deviation: 1.43 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2_ukrIejrd8",
        "outputId": "ca06780b-c268-401b-f9b0-d1634b6687fe"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 4)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 29.11 %\n",
            "Standard Deviation: 1.79 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSRCA3NOWFdI",
        "outputId": "f964549f-dc20-4d55-d5da-f8f37aa1c67b"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 8)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 30.68 %\n",
            "Standard Deviation: 2.90 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T67OmzT0KJ-e",
        "outputId": "0bb0f320-3929-40e1-99ae-6b3345110359"
      },
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 31.77 %\n",
            "Standard Deviation: 5.59 %\n"
          ]
        }
      ]
    }
  ]
}